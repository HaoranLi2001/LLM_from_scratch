{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hyEfALTuvK5q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn([2,3])\n",
        "print(a)\n",
        "print(a.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaHYufykvW0y",
        "outputId": "9c4afaad-4a3b-4798-baff-349bf8a70080"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6756, -0.3473,  0.1252],\n",
            "        [-1.2120,  0.1400, -0.1038]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randn([2,3])\n",
        "print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ecXnxdtviY0",
        "outputId": "42ded035-1800-4fb6-a56f-7bbf53e6a555"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.6690,  1.1527,  1.1440],\n",
            "        [-0.6459, -0.2247,  2.2357]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.cat([a, b], dim = 0)\n",
        "print(c)\n",
        "print(c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TehS3kXP7-Yi",
        "outputId": "b84c6d9f-0a01-43a9-9f47-835c8e0b47ff"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6756, -0.3473,  0.1252],\n",
            "        [-1.2120,  0.1400, -0.1038],\n",
            "        [-1.6690,  1.1527,  1.1440],\n",
            "        [-0.6459, -0.2247,  2.2357]])\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class basicExpert(nn.Module):\n",
        "  def __init__(self, feature_in, feature_out):\n",
        "    super().__init__()\n",
        "\n",
        "    self.expert = nn.Linear(feature_in, feature_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.expert(x)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "OKQp8QNov_dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class basicMOE(nn.Module):\n",
        "  def __init__(self, feature_in, feature_out, num_experts):\n",
        "    super().__init__()\n",
        "\n",
        "    self.experts = nn.ModuleList(\n",
        "        [\n",
        "            nn.Linear(feature_in, feature_out) for _ in range(num_experts)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    self.gate = nn.Linear(feature_in, num_experts)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x.size = (batch, feature_in)\n",
        "    print(f'shape of x: {x.shape}')\n",
        "    expert_weight = self.gate(x) # weight.shape = (batch, num_experts)\n",
        "    expert_weight = expert_weight.unsqueeze(1) # weight.shape = (batch, 1, num_experts)\n",
        "    print(f'shape of weight: {expert_weight.shape}')\n",
        "\n",
        "    expert_output = [\n",
        "        expert(x).unsqueeze(1) for expert in self.experts\n",
        "    ]\n",
        "    # for i, eo in enumerate(expert_output):\n",
        "    #   print(f'shape of {i}-th expert output: {eo.size()}')\n",
        "\n",
        "    expert_output = torch.cat(expert_output, dim = 1) # output.shape = (batch, num_experts, feature_out)\n",
        "    print(f'shape of output: {expert_output.shape}')\n",
        "\n",
        "    output = expert_weight @ expert_output\n",
        "    # print(f'shape of output: {output.shape}')\n",
        "    return output\n",
        "\n",
        "def testMOE(x, feature_in, feature_out, num_experts):\n",
        "  x = torch.randn([5,2])\n",
        "  moe = basicMOE(feature_in, feature_out, number_experts)\n",
        "  output = moe(x)\n",
        "  print(f'test shape: {output.shape}')\n",
        "\n",
        "batch = 5\n",
        "feature_in = 2\n",
        "feature_out = 4\n",
        "number_experts = 3\n",
        "x = torch.randn([batch, feature_in])\n",
        "testMOE(x, feature_in, feature_out, number_experts)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdEyWvPt0ti7",
        "outputId": "d9589b79-337a-4230-9678-4379f0bd56dd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x: torch.Size([5, 2])\n",
            "shape of weight: torch.Size([5, 1, 3])\n",
            "shape of output: torch.Size([5, 3, 4])\n",
            "test shape: torch.Size([5, 1, 4])\n"
          ]
        }
      ]
    }
  ]
}