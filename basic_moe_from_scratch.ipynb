{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hyEfALTuvK5q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class basicExpert(nn.Module):\n",
        "  def __init__(self, feature_in, feature_out):\n",
        "    super().__init__()\n",
        "\n",
        "    self.expert = nn.Linear(feature_in, feature_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.expert(x)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "OKQp8QNov_dg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class basicMOE(nn.Module):\n",
        "  def __init__(self, feature_in, feature_out, num_experts):\n",
        "    super().__init__()\n",
        "\n",
        "    self.experts = nn.ModuleList(\n",
        "        [\n",
        "            nn.Linear(feature_in, feature_out) for _ in range(num_experts)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    self.gate = nn.Linear(feature_in, num_experts)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x.size = (batch, feature_in)\n",
        "    print(f'shape of x: {x.shape}')\n",
        "    expert_weight = self.gate(x) # weight.shape = (batch, num_experts)\n",
        "    expert_weight = expert_weight.unsqueeze(1) # weight.shape = (batch, 1, num_experts)\n",
        "    print(f'shape of weight: {expert_weight.shape}')\n",
        "\n",
        "    expert_output = [\n",
        "        expert(x).unsqueeze(1) for expert in self.experts\n",
        "    ]\n",
        "\n",
        "    expert_output = torch.cat(expert_output, dim = 1) # output.shape = (batch, num_experts, feature_out)\n",
        "    print(f'shape of output: {expert_output.shape}')\n",
        "\n",
        "    output = expert_weight @ expert_output\n",
        "    # print(f'shape of output: {output.shape}')\n",
        "    return output.squeeze()\n",
        "\n",
        "def testMOE(x, feature_in, feature_out, num_experts):\n",
        "  x = torch.randn([5,2])\n",
        "  moe = basicMOE(feature_in, feature_out, number_experts)\n",
        "  output = moe(x)\n",
        "  print(f'test shape: {output.shape}')\n",
        "\n",
        "batch = 5\n",
        "feature_in = 2\n",
        "feature_out = 4\n",
        "number_experts = 3\n",
        "x = torch.randn([batch, feature_in])\n",
        "testMOE(x, feature_in, feature_out, number_experts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdEyWvPt0ti7",
        "outputId": "382e95d0-f61d-4641-88f4-5c8f31c67f8e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x: torch.Size([5, 2])\n",
            "shape of weight: torch.Size([5, 1, 3])\n",
            "shape of output: torch.Size([5, 3, 4])\n",
            "test shape: torch.Size([5, 4])\n"
          ]
        }
      ]
    }
  ]
}